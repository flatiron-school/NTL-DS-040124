{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.impute import MissingIndicator, SimpleImputer\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, RocCurveDisplay, confusion_matrix, roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> The goal here is to illustrate a possible workflow for classification modeling with `sklearn`'s `LogisticRegression` model.\n",
    "\n",
    "\n",
    "- Formulate and implement an iterative modeling workflow\n",
    "- Implement pipeline workflow to improve efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Modeling Walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Modeling Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. Build a model based on the [Titanic dataset](https://www.kaggle.com/c/titanic/data) that predicts whether a given person survived or not\n",
    "2. Evaluate the performance of the model\n",
    "3. Make changes in an attempt to improve the model\n",
    "4. Demonstrate whether an improvement was made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This dataset has the following columns:\n",
    "\n",
    "| Variable | Definition | Key |\n",
    "| -------- | ---------- | --- |\n",
    "| survival | Survival | 0 = No, 1 = Yes |\n",
    "| pclass | Ticket class | 1 = 1st, 2 = 2nd, 3 = 3rd |\n",
    "| sex | Sex | |\n",
    "| Age | Age in years | |\n",
    "| sibsp | # of siblings / spouses aboard the Titanic | |\n",
    "| parch | # of parents / children aboard the Titanic | |\n",
    "| ticket | Ticket number | |\n",
    "| fare | Passenger fare | |\n",
    "| cabin | Cabin number | |\n",
    "| embarked | Port of Embarkation | C = Cherbourg, Q = Queenstown, S = Southampton |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Initial Data Understanding and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Open up the file, get everything into `X` features and `y` target variables, divided into train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/titanic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Age data is missing for about 1 in 5 rows in our dataset.  For now, let's just exclude it, plus the non-numeric columns, and `PassengerId`, which doesn't seem like a real feature, but rather just an artifact of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = df.drop(\"PassengerId\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Pclass are numbers but it's not clear that the difference between 1st and 2nd is the\n",
    "# same as the difference between 2nd and 3rd\n",
    "numeric_columns = [\"Survived\", \"SibSp\", \"Parch\", \"Fare\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(df[numeric_columns]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "numeric_df = df[numeric_columns]\n",
    "X = numeric_df.drop(\"Survived\", axis=1)\n",
    "y = numeric_df[\"Survived\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 1st Model - \"Dummy\" Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's start with a completely \"dummy\" model, that will always choose the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dummy_model = DummyClassifier(strategy=\"most_frequent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Fit the model on our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dummy_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We should expect all predictions to be the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# just grabbing the first 50 to save space\n",
    "dummy_model.predict(X_train)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's do some cross-validation to see how the model would do in generalizing to new data it's never seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cv_results = cross_val_score(dummy_model, X_train, y_train, cv=5)\n",
    "cv_results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "So, the mean accuracy is a little under 62% if we always guess the majority class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To show the spread, let's make a convenient class that can help us organize the model and the cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class ModelWithCV():\n",
    "    '''Structure to save the model and more easily see its crossvalidation'''\n",
    "    \n",
    "    def __init__(self, model, model_name, X, y, cv_now=True):\n",
    "        self.model = model\n",
    "        self.name = model_name\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        # For CV results\n",
    "        self.cv_results = None\n",
    "        self.cv_mean = None\n",
    "        self.cv_median = None\n",
    "        self.cv_std = None\n",
    "        #\n",
    "        if cv_now:\n",
    "            self.cross_validate()\n",
    "        \n",
    "    def cross_validate(self, X=None, y=None, kfolds=10):\n",
    "        '''\n",
    "        Perform cross-validation and return results.\n",
    "        \n",
    "        Args: \n",
    "          X:\n",
    "            Optional; Training data to perform CV on. Otherwise use X from object\n",
    "          y:\n",
    "            Optional; Training data to perform CV on. Otherwise use y from object\n",
    "          kfolds:\n",
    "            Optional; Number of folds for CV (default is 10)  \n",
    "        '''\n",
    "        \n",
    "        cv_X = X if X else self.X\n",
    "        cv_y = y if y else self.y\n",
    "\n",
    "        self.cv_results = cross_val_score(self.model, cv_X, cv_y, cv=kfolds)\n",
    "        self.cv_mean = np.mean(self.cv_results)\n",
    "        self.cv_median = np.median(self.cv_results)\n",
    "        self.cv_std = np.std(self.cv_results)\n",
    "\n",
    "        \n",
    "    def print_cv_summary(self):\n",
    "        cv_summary = (\n",
    "        f'''CV Results for `{self.name}` model:\n",
    "            {self.cv_mean:.5f} ± {self.cv_std:.5f} accuracy\n",
    "        ''')\n",
    "        print(cv_summary)\n",
    "\n",
    "        \n",
    "    def plot_cv(self, ax):\n",
    "        '''\n",
    "        Plot the cross-validation values using the array of results and given \n",
    "        Axis for plotting.\n",
    "        '''\n",
    "        ax.set_title(f'CV Results for `{self.name}` Model')\n",
    "        # Thinner violinplot with higher bw\n",
    "        sns.violinplot(y=self.cv_results, ax=ax, bw=.4)\n",
    "        sns.swarmplot(\n",
    "                y=self.cv_results,\n",
    "                color='orange',\n",
    "                size=10,\n",
    "                alpha= 0.8,\n",
    "                ax=ax\n",
    "        )\n",
    "\n",
    "        return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dummy_model_results = ModelWithCV(\n",
    "                        model=dummy_model,\n",
    "                        model_name='dummy',\n",
    "                        X=X_train, \n",
    "                        y=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax = dummy_model_results.plot_cv(ax)\n",
    "plt.tight_layout();\n",
    "\n",
    "dummy_model_results.print_cv_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "fig.suptitle(\"Dummy Model\")\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_train, dummy_model.predict(X_train))).plot(ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A pretty lopsided confusion matrix!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_train, dummy_model.predict_proba(X_train)[:,1])\n",
    "RocCurveDisplay(fpr=fpr, tpr=tpr).plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 2nd Model - Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's use a logistic regression and compare its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We're going to specifically avoid any regularization (the default) to see how the model does with little change. So we'll pass `'none'` to the `penalty` parameter to not use any regularization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "simple_logreg_model = LogisticRegression(random_state=2023, penalty='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "simple_logreg_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Look at the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "simple_logreg_model.predict(X_train)[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Mixture of 1s and 0s this time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Model Evaluation, Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "simple_logreg_results = ModelWithCV(\n",
    "                        model=simple_logreg_model,\n",
    "                        model_name='simple_logreg',\n",
    "                        X=X_train, \n",
    "                        y=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Saving variable for convenience\n",
    "model_results = simple_logreg_results\n",
    "\n",
    "# Plot CV results\n",
    "fig, ax = plt.subplots()\n",
    "ax = model_results.plot_cv(ax)\n",
    "plt.tight_layout();\n",
    "# Print CV results\n",
    "model_results.print_cv_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_logreg_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "So the mean accuracy is better when the model is actually taking in information from the features instead of always guessing the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_train, simple_logreg_model.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "fig.suptitle(\"Logistic Regression with Numeric Features Only\")\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_train, simple_logreg_model.predict(X_train))).plot(ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "So, in general we are not labeling many of the \"not survived\" passengers as \"survived\", but for \"survived\" passengers we're getting it wrong most of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_train, simple_logreg_model.predict_proba(X_train)[:,1])\n",
    "RocCurveDisplay(fpr=fpr, tpr=tpr).plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This model is doing better than just choosing the most frequent class every time, but it probably could do better. \n",
    "\n",
    "We can say this model is likely underfitting, which means we need _more complexity_. We can add more complexity a few different ways. We'll try doing some feature engineering/data preparation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Back to Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Maybe there is some useful information in the features we are not using yet.  Let's go wild and add all of them!\n",
    "\n",
    "> Note: you can and should add features incrementally in a \"real\" modeling context.  The engineering effort of encoding the variables can be non-trivial!  But here let's assume that it's not too much work to encode all of them.\n",
    "\n",
    "Start with a new train-test split that contains all of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X = df.drop(\"Survived\", axis=1)\n",
    "y = df[\"Survived\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Better Process: Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Pipelines** can keep our code neat and clean all the way from gathering & cleaning our data, to creating models & fine-tuning them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://imgs.xkcd.com/comics/data_pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Pipeline` class from [Scikit-Learn's API](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) is especially convenient since it allows us to use our other Estimators that we know and love!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advantages of `Pipeline`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduces Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You can focus on particular parts of the pipeline one at a time and debug or adjust parts as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convenient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The pipeline summarizes your fine-detail steps. That way you can focus on the big-picture aspects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flexible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You can use pipelines with different models and with GridSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prevent Mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We can focus on one section at a time.\n",
    ">\n",
    "> We also can ensure data leakage between our training and doesn't occur between our training dataset and validation/testing datasets!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing Column Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Allows one to run different transformers on seperate columns in seamless step with each other. Let's try to add in imputation, and One Hot Encoding. We are creating 'mini' pipelines for each step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's be extra cautious and make a separate column to indicate whether there originally was a missing value.\n",
    "\n",
    "In our training data there are only missing values for a couple of the columns, but we can't be sure about where the test set will be missing data.\n",
    "\n",
    "The `MissingIndicator` from `sklearn` will mark the missing values in an input array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "indicator_demo = MissingIndicator()\n",
    "\n",
    "indicator_demo.fit(X_train)\n",
    "\n",
    "indicator_demo.features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "indicator_demo.transform(X_train)[:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.iloc[:5, [3, 8, 9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cabin'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now that we've specified which values were originally missing, let's fill in those missing values.  This takes two separate imputers because we want to use the mean for numeric data and the majority class for categorical data.\n",
    "\n",
    "The `SimpleImputer` class fills in the mean value by default, so we'll have to override that for the categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputers\n",
    "num_imput = None\n",
    "cat_imput = None\n",
    "\n",
    "# Pipelines\n",
    "num_pipeline = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you wanted to drop\n",
    "def drop_func():\n",
    "    pass\n",
    "    \n",
    "from sklearn.preprocessing import FunctionTransformer    \n",
    "\n",
    "drop_sklearn = FunctionTransformer(drop_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now that there are no missing values, convert all of the categorical features into numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipeline = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bring them back together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feats = ['Age', 'SibSp', 'Parch', 'Fare']\n",
    "cat_feats = ['Pclass', 'Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_tr = ColumnTransformer(transformers=[('num', num_pipeline, num_feats),\n",
    "                                        ('cat', cat_pipeline, cat_feats)],\n",
    "                          remainder='passthrough', sparse_threshold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "col_tr.fit_transform(X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "col_tr.transform(X_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Ticket'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is...a ridiculous number of columns.  How did we end up with more columns than rows?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 3rd Model - After More Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's run a logistic regression:\n",
    "> We can incorporate both our Column Transformer and a model into a final top level Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Bring in column transformer and a last step estimator/model\n",
    "log_pipe = Pipeline(steps=[('ct', col_tr),\n",
    "                           ('logreg', LogisticRegression(random_state=42, penalty='none'))])\n",
    "\n",
    "log_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What happened there?  This solver had no problem before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Hyperparameter Adjustments to the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's try a couple of stopgap measures to get the model to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### More Iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Allows for more iterations to find a solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log_pipe2 = log_pipe = Pipeline(steps=[('ct', col_tr), \n",
    "                           ('logreg', LogisticRegression(random_state=42, penalty='none',\n",
    "                                                         max_iter = 1000))])\n",
    "\n",
    "log_pipe2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### More Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Remember that the `C` parameter is the inverse of the regularization strength."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> Note: We could do regularization but we should first scale our features. We're actually going to skip this hyperparameter until we scale our data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Higher Tolerance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A higher tolerance means that the model will stop training earlier (when predictions and true values aren't as close as they could be)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_pipe3 = Pipeline(steps=[('ct', col_tr), \n",
    "                           ('logreg', LogisticRegression(random_state=42, penalty='none', \n",
    "                                                         tol=25))])\n",
    "\n",
    "log_pipe3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fix, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 6))\n",
    "\n",
    "axes[0].set_title(\"More Iterations\")\n",
    "axes[1].set_title(\"Higher Tolerance\")\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_train, log_pipe2.predict(X_train))).plot(ax=axes[0])\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_train, log_pipe3.predict(X_train))).plot(ax=axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "logreg_model_more_iterations_results = ModelWithCV(\n",
    "                                        log_pipe2,\n",
    "                                        'more_iterations',\n",
    "                                        X_train,\n",
    "                                        y_train\n",
    ")\n",
    "    \n",
    "logreg_model_higher_tolerance_results = ModelWithCV(\n",
    "                                        log_pipe3,\n",
    "                                        'higher_tolerance',\n",
    "                                        X_train,\n",
    "                                        y_train\n",
    ")\n",
    "\n",
    "models = [\n",
    "    logreg_model_more_iterations_results,\n",
    "    logreg_model_higher_tolerance_results\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pipe2.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pipe3.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f,axes = plt.subplots(ncols=2, sharey=True, figsize=(12, 6))\n",
    "\n",
    "for ax, result in zip(axes, models):\n",
    "    ax = result.plot_cv(ax)\n",
    "    result.print_cv_summary()\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "fpr2, tpr2, thresh2 = roc_curve(y_train, log_pipe2.predict_proba(X_train)[:,1]) \n",
    "fpr3, tpr3, thresh3 = roc_curve(y_train, log_pipe3.predict_proba(X_train)[:,1])\n",
    "\n",
    "RocCurveDisplay(fpr=fpr2, tpr=tpr2).plot(ax=ax)\n",
    "RocCurveDisplay(fpr=fpr3, tpr=tpr3).plot(ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> What can we observe from these two adjustments to our model with more features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Even More Data Preparation - Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We saw that our last model is overfitting on so many features. A good strategy is to do regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "However, recall we should scale all of the features, so the model isn't overly penalizing age and fare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_pipeline2 = Pipeline(steps=[('im_num', SimpleImputer(add_indicator=True)), \n",
    "                               ('ss', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "col_tr2 = ColumnTransformer(transformers=[('num', num_pipeline2, num_feats),\n",
    "                                        ('cat', cat_pipeline, cat_feats)],\n",
    "                          remainder='passthrough', sparse_threshold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pipe4 = Pipeline([('ct', col_tr2), ('logreg', LogisticRegression(random_state=42))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 4th Model - After Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now that the data is scaled, let's see if we can fit the model without tweaking any hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_pipe4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Model Evaluation, Part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now that we are able to run a logistic regression with default hyperparameters, let's see how that performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "fig.suptitle(\"Logistic Regression with All Features, Scaled\")\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_train, log_pipe4.predict(X_train))).plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pipe4.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_results = ModelWithCV(\n",
    "                            log_pipe4,\n",
    "                            'all_features',\n",
    "                            X_train,\n",
    "                            y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plot CV results\n",
    "fig, ax = plt.subplots()\n",
    "ax = model_results.plot_cv(ax)\n",
    "plt.tight_layout();\n",
    "# Print CV results\n",
    "model_results.print_cv_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fpr4, tpr4, thresh4 = roc_curve(y_train, log_pipe4.predict_proba(X_train)[:,1])\n",
    "\n",
    "RocCurveDisplay(fpr=fpr4, tpr=tpr4).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Doing good on the training data, ~81% range on the test data ... this model is still overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We should try hard feature elimination "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall what was happening with our name and ticket columns (OHE creating too many columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feats = ['Age', 'SibSp', 'Parch', 'Fare']\n",
    "cat_feats = ['Pclass', 'Sex', 'Cabin', 'Embarked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_tr3 = ColumnTransformer(transformers=[('num', num_pipeline2, num_feats),\n",
    "                                        ('cat', cat_pipeline, cat_feats)],\n",
    "                          remainder='passthrough', sparse_threshold=0)\n",
    "\n",
    "log_pipe5 = Pipeline([('ct', col_tr3), ('logreg', LogisticRegression(random_state=42))])\n",
    "log_pipe5.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "fig.suptitle(\"Logistic Regression with Less Features, Scaled\")\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_train, log_pipe5.predict(X_train))).plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pipe5.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = ModelWithCV(\n",
    "                            log_pipe5,\n",
    "                            'less_features',\n",
    "                            X_train,\n",
    "                            y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CV results\n",
    "fig, ax = plt.subplots()\n",
    "ax = model_results.plot_cv(ax)\n",
    "plt.tight_layout();\n",
    "# Print CV results\n",
    "model_results.print_cv_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr4, tpr4, thresh4 = roc_curve(y_train, log_pipe5.predict_proba(X_train)[:,1])\n",
    "\n",
    "RocCurveDisplay(fpr=fpr4, tpr=tpr4).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## `SelectFromModel`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The all features model was probably overfitting. We might try thinning out the number of features by eliminating the ones with small modeling coefficients using [`SelectFromModel`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selector = SelectFromModel(log_pipe4)\n",
    "\n",
    "selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We're using the default threshold here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "thresh = selector.threshold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pipe4.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_pipe4.named_steps['logreg'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tr = col_tr2.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectFromModel(LogisticRegression(random_state=42))\n",
    "selector.fit(X_train_tr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "thresh = selector.threshold_\n",
    "thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's get a sense of which features will be eliminated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "coefs = selector.estimator_.coef_\n",
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coefs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "coefs[abs(coefs) > thresh].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sel = selector.transform(X_train_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_sel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_6 = LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_6.fit(X_train_sel, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Save for later comparison\n",
    "select_results = ModelWithCV(\n",
    "                    log_reg_6, \n",
    "                    'logreg_sel',\n",
    "                    X_train_sel,\n",
    "                    y_train\n",
    ")\n",
    "\n",
    "# Plot both all_features vs new model\n",
    "f,axes = plt.subplots(ncols=2, sharey='all', figsize=(12, 6))\n",
    "\n",
    "model_results.plot_cv(ax=axes[0])\n",
    "select_results.plot_cv(ax=axes[1])\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"Old:\", model_results.cv_results.mean())\n",
    "print(\"New:\", select_results.cv_results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Probably still overfitting, but let's call this our final model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Final Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now that we have a final model, we would transform our X_test in accordance to what we did to X_train: Missing Indicators, Imputations, One Hot Encoding, Scaling, etc...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Create a model with the relevant hyperparameters, fit, and score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tr = col_tr2.transform(X_test)\n",
    "X_test_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sel = selector.transform(X_test_tr)\n",
    "X_test_sel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_model = LogisticRegression(random_state=42)\n",
    "\n",
    "final_model.fit(X_train_sel, y_train)\n",
    "\n",
    "final_model.score(X_test_sel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model2 = Pipeline(steps=[('ct', col_tr2),\n",
    "                               ('selector', SelectFromModel(LogisticRegression(random_state=42))),\n",
    "                               ('logreg', LogisticRegression(random_state=42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_model2.fit(X_train, y_train)\n",
    "final_model2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "fig.suptitle(\"Final Model\")\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, final_model2.predict(X_test))).plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresh = roc_curve(y_test, final_model2.predict_proba(X_train)[:,1])\n",
    "\n",
    "RocCurveDisplay(fpr=fpr, tpr=tpr).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, final_model2.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Build and iterate on a logistic regression model of **color** for the diamonds dataset! Maximize accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "diamonds = sns.load_dataset('diamonds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "TOC",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
