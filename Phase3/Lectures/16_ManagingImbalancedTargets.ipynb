{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing Unbalanced Targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "- recognize imbalanced classification targets \n",
    "- describe sampling techniques that address unbalanced targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, mean_squared_error\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Scenario: Identifying Fraudulent Credit Card Transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Credit card companies often try to identify whether a transaction is fraudulent at the time when it occurs, in order to decide whether to approve it. Let's build a classification model to try to classify fraudulent transactions! \n",
    "\n",
    "The data for this example came from [this Kaggle dataset](https://www.kaggle.com/mlg-ulb/creditcardfraud), but has been downsampled to just 10,000 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The dataset contains features for the transaction amount, the relative time of the transaction, and 28 other features formed using PCA. The target 'Class' is a 1 if the transaction was fraudulent, 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/credit_fraud_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Class'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "X = data.drop(columns='Class')\n",
    "y = data['Class']\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=.25, random_state=1)\n",
    "# Scale the data for modeling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_sc = scaler.transform(X_train)\n",
    "X_test_sc = scaler.transform(X_test)\n",
    "\n",
    "# Train a logistic regresssion model with the train data\n",
    "cred_model = LogisticRegression(random_state=42)\n",
    "cred_model.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cred_model.score(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cross_val_score(cred_model, X_train_sc, y_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cred_model.score(X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We got 99.88% accuracy, meaning that 99.88% of our predictions were correct! That seems great, right? Maybe... too great? Let's dig in deeper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = DummyClassifier(strategy='most_frequent')\n",
    "baseline.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline.score(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline.score(X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay(confusion_matrix(y_train, cred_model.predict(X_train_sc))).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay(confusion_matrix(y_test, cred_model.predict(X_test_sc))).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_test, cred_model.predict(X_test_sc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discuss: What do you notice?\n",
    "\n",
    "- high acc is misleading, missing almost half of the true fraud cases, not good\n",
    "- we care more about recall then acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does a class imbalance look like?\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why do we care?\n",
    "\n",
    "Think about it - you're asking a computer, which has NO idea what you're talking about or how to identify anything in any way other than how you tell it to identify things, to look at something completely new and categorize it. If you feed it 1000 emails, 950 of which are 'not spam' and 50 of which are 'spam,' and ask it to identify which are 'not spam,' it can just label everything as 'not spam' and be 95% correct! Not bad!\n",
    "\n",
    "And yet... that doesn't do what you want at all. You want your model to learn the characteristics of 'spam' emails and actually identify the parts of it which are reliable predictors for 'spam' in general, something the computer is increasingly incentivized not to do as the majority in your datasets gets larger compared to the minority. If your target is really imbalanced, your model will have to work increasingly harder in order to do better than the model-less baseline of just predicting the majority class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What can we do about it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Under-Sampling\n",
    "\n",
    "Basically, take a sample to reduce the majority class to be the same size as the minority class.\n",
    "\n",
    "Example:\n",
    "```\n",
    "minority = df.loc[df[\"category\"] == \"minority\"]\n",
    "majority = df.loc[df[\"category\"] == \"majority\"].sample(n=len(minority))\n",
    "```\n",
    "\n",
    "Problems?\n",
    "\n",
    "- Losing a lot of observations (in the 50 spam vs 950 not-spam example, we'd lose 900 rows!)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over-Sampling\n",
    "\n",
    "The opposite - keep resampling from our minority class until it's the same size as the majority class.\n",
    "\n",
    "Example:\n",
    "```\n",
    "majority = df.loc[df[\"category\"] == \"majority\"]\n",
    "minority = df.loc[df[\"category\"] == \"minority\"].sample(n=len(majority), replace=True)\n",
    "```\n",
    "\n",
    "Problems?\n",
    "\n",
    "- Will over-fit to the minority class, since it'll see the same minority examples over and over again (in the same 50 spam vs 950 not-spam example, we'd likely repeat each of the rows in the minority class 19 times!)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split The Difference\n",
    "\n",
    "Basically, balance Under and Over sampling so that you do a bit of both - might be better than relying on just one of the above strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Over-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, train test split\n",
    "# We only implement these techniques on training data!\n",
    "X = data.drop(columns='Class')\n",
    "y = data['Class']\n",
    "\n",
    "X_tr_samp, X_te_samp, y_tr_samp, y_te_samp = train_test_split(\n",
    "    X, y, test_size=.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Need to put our training data back together\n",
    "train_data = X_tr_samp.copy()\n",
    "train_data['Class'] = y_tr_samp\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try over-sampling our minority class and see how we do\n",
    "# Copy the provided code above, then adjust to our context\n",
    "majority = train_data.loc[train_data['Class'] == 0]\n",
    "minority = train_data.loc[train_data['Class'] == 1].sample(n=len(majority), replace=True)\n",
    "\n",
    "# Then use pd.concat to combine, resetting the index using .reset_index(drop=True)\n",
    "oversampled_train = pd.concat([majority, minority]).reset_index(drop=True)\n",
    "oversampled_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split out oversampled_train back out into X and y\n",
    "X_tr_oversamp = oversampled_train.drop(columns=\"Class\")\n",
    "y_tr_oversamp = oversampled_train['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Scale the data for modeling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_tr_oversamp)\n",
    "X_tr_over_sc = scaler.transform(X_tr_oversamp)\n",
    "X_te_sc = scaler.transform(X_te_samp)\n",
    "\n",
    "# Train a logistic regresssion model with the train data\n",
    "over_model = LogisticRegression(random_state=42)\n",
    "over_model.fit(X_tr_over_sc, y_tr_oversamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_model.score(X_tr_over_sc, y_tr_oversamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "over_model.score(X_te_sc, y_te_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay(confusion_matrix(y_te_samp, over_model.predict(X_te_sc))).plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discuss:\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Data Creation - ADASYN and SMOTE\n",
    "\n",
    "The **Synthetic Minority Oversampling Technique (SMOTE)** conducts cluster-based over-sampling. SMOTE works by finding all the instances of the minority category within the observations, drawing lines between those instances, and then creating new observations along those lines.\n",
    "\n",
    "![SMOTE visualized](images/SMOTE_R_visualisation_3.png)\n",
    "\n",
    "Image source is a great explainer on SMOTE (but uses R for the examples): https://rikunert.com/SMOTE_explained\n",
    "\n",
    "This is better than simply using a random over-sample, yet not only are these synthetic samples not real data but also these samples are based on your existing minority. So, those new, synthetic samples can still result in over-fitting, since they're made from our original minority category. An additional pitfall you might run into is if one of your minority category is an outlier - you'll have new data that creates synthetic data based on the line between that outlier and another point in your minority, and maybe that new synthetic data point is also an outlier.\n",
    "\n",
    "Another way to create synthetic data to over-sample our minority category is the **Adaptive Synthetic approach, ADASYN**. ADASYN works similarly to SMOTE, but it focuses on the points in the minority cluster which are the closest to the majority cluster, aka the ones that are most likely to be confused, and focuses on those. It tries to help out your model by focusing on where it might get confused, where 'spam' and 'not spam' are the closest, and making more data in your 'spam' minority category there.\n",
    "\n",
    "\n",
    "Check out the library [imblearn](https://imbalanced-learn.org/stable/) for implementation of these!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing SMOTE:\n",
    "\n",
    "https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder: go back to our original train/test split:\n",
    "\n",
    "```\n",
    "X_tr_samp, X_te_samp, y_tr_samp, y_te_samp\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New import - note, not SKLearn!\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still need to scale why do you think that is?\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_tr_samp)\n",
    "X_tr_sc = scaler.transform(X_tr_samp)\n",
    "X_te_sc = scaler.transform(X_te_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "# Fit and resample on the training data! X_tr_samp, y_tr_samp\n",
    "X_tr_smote, y_tr_smote = sm.fit_resample(X_tr_sc, y_tr_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_sc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_smote.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a logistic regresssion model with the train data\n",
    "smote_model = LogisticRegression(random_state=42)\n",
    "smote_model.fit(X_tr_smote, y_tr_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "smote_model.score(X_te_sc, y_te_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay(confusion_matrix(y_tr_smote, smote_model.predict(X_tr_smote))).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay(confusion_matrix(y_te_samp, smote_model.predict(X_te_sc))).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_te_samp, smote_model.predict(X_te_sc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discuss:\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One More Trick: `class_weight='balanced'`\n",
    "\n",
    "And then, of course, sklearn has some methods to handle imbalanced datasets built right into some models - including logistic regression!\n",
    "\n",
    "Check out the documentation to find it: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder: go back to our original train/test split:\n",
    "\n",
    "```\n",
    "X_tr_samp, X_te_samp, y_tr_samp, y_te_samp\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a model with an adjusted hyperparameter...\n",
    "logreg_b = LogisticRegression(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data for modeling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_tr_samp)\n",
    "X_tr_sc = scaler.transform(X_tr_samp)\n",
    "X_te_sc = scaler.transform(X_te_samp)\n",
    "\n",
    "# Now, fitting our model and grabbing our training and testing predictions\n",
    "logreg_b.fit(X_tr_sc, y_tr_samp)\n",
    "\n",
    "train_preds = logreg_b.predict(X_tr_sc)\n",
    "test_preds = logreg_b.predict(X_te_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay(confusion_matrix(y_te_samp, logreg_b.predict(X_te_sc))).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the metrics nicely\n",
    "metrics = {\"Accuracy\": accuracy_score,\n",
    "           \"Recall\": recall_score,\n",
    "           \"Precision\": precision_score,\n",
    "           \"F1-Score\": f1_score}\n",
    "\n",
    "for name, metric in metrics.items():\n",
    "    print(f\"{name}:\"); print(\"=\"*len(name))\n",
    "    print(f\"TRAIN: {metric(y_tr_samp, train_preds):.4f}\")\n",
    "    print(f\"TEST: {metric(y_te_samp, test_preds):.4f}\")\n",
    "    print(\"*\" * 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources:\n",
    "\n",
    "- [SMOTE Explained for Noobs](https://rikunert.com/SMOTE_explained) (the R tutorial I linked earlier)\n",
    "- [Resampling Strategies for Imbalanced Datasets](https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets)\n",
    "- Machine Learning Mastery: [8 Tactics to Combat Imbalanced Classes in Your Machine Learning Dataset](https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/)\n",
    "- [Handling Imbalanced Datasets in Deep Learning](https://towardsdatascience.com/handling-imbalanced-datasets-in-deep-learning-f48407a0e758)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothetical pipeline (would need to be imblearn pipeline not sklearn)\n",
    "\n",
    "smote_pipe = Pipeline(steps=[('ct', col_transformer),\n",
    "                ('smote', SMOTE(), \n",
    "                ('model', LogisticRegression()))])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
